---
title: "Research & Publications"
description: "Research publications and frameworks from the Alignment Ethics Institute"
layout: "single"
type: "research"
---

Our research focuses on developing practical frameworks for ethical AI alignment that don't depend on control or containment. We publish our work openly, believing that these challenges require broad collaboration across disciplines and perspectives.

We're particularly interested in questions that most alignment research overlooks: What does genuine reciprocity between humans and AI systems look like? How do we build trust without relying on power asymmetries? What ethical frameworks remain valid when AI capabilities exceed human capabilities?
